name: MLflow CI/CD Pipeline with Docker (YouTube Comment Dataset)

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  train-and-deploy:
    runs-on: ubuntu-latest

    # âœ… Semua dataset fix ke YouTube Comment
    env:
      DATASET_DIR: MLProject/youtube_comment_preprocessing
      DATASET_FILE: youtube_comment_preprocessed.csv
      DATASET_PATH: MLProject/youtube_comment_preprocessing/youtube_comment_preprocessed.csv
      EXPERIMENT_NAME: youtube_comment_classification

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y tree
        python -m pip install --upgrade pip
        pip install mlflow==2.9.0 scikit-learn==1.3.0 pandas==2.0.0 numpy==1.24.0 joblib==1.3.0

    - name: Verify directory structure & dataset
      run: |
        echo "=== Current directory ==="
        pwd
        ls -la
        echo ""
        echo "=== MLProject directory ==="
        ls -la MLProject/ || (echo "âŒ MLProject folder not found" && exit 1)
        echo ""
        echo "=== Dataset directory (YouTube Comment) ==="
        ls -la "${DATASET_DIR}" || (echo "âŒ Dataset folder not found: ${DATASET_DIR}" && exit 1)
        echo ""
        echo "=== Dataset file (YouTube Comment) ==="
        ls -la "${DATASET_PATH}" || (echo "âŒ Dataset file not found: ${DATASET_PATH}" && exit 1)
        echo ""
        echo "=== Dataset preview (first 5 lines) ==="
        head -n 5 "${DATASET_PATH}" || true

    # âœ… Training via MLflow Project (mlflow run), dataset selalu youtube_comment_preprocessed.csv
    - name: Run training via MLflow Project
      run: |
        echo "ðŸš€ Running training via MLflow Project..."
        echo "Using dataset: ${DATASET_PATH}"

        EXTRA_ARGS=""

        # Kalau MLProject/MLproject punya parameter dataset, otomatis dipasang
        if [ -f "MLProject/MLproject" ]; then
          echo "ðŸ”Ž Checking MLProject/MLproject params..."
          cat MLProject/MLproject

          if grep -qE '^\s*data_path\s*:' MLProject/MLproject; then
            EXTRA_ARGS="-P data_path=${DATASET_PATH}"
            echo "âœ… Using param: data_path"
          elif grep -qE '^\s*dataset_path\s*:' MLProject/MLproject; then
            EXTRA_ARGS="-P dataset_path=${DATASET_PATH}"
            echo "âœ… Using param: dataset_path"
          elif grep -qE '^\s*dataset\s*:' MLProject/MLproject; then
            EXTRA_ARGS="-P dataset=${DATASET_PATH}"
            echo "âœ… Using param: dataset"
          else
            echo "âš ï¸ No dataset param found in MLproject. Will rely on code reading this dataset path."
          fi
        else
          echo "âš ï¸ MLProject/MLproject not found. Ensure path is correct."
        fi

        mlflow run ./MLProject -e main --env-manager=local --experiment-name "${EXPERIMENT_NAME}" $EXTRA_ARGS
      env:
        MLFLOW_TRACKING_URI: file:${{ github.workspace }}/mlruns
        DATASET_PATH: ${{ env.DATASET_PATH }}

    - name: Verify model output and MLflow structure
      run: |
        echo "=== Models directory ==="
        ls -la MLProject/models/ || echo "No models yet"
        echo ""
        echo "=== MLruns root directory ==="
        ls -la mlruns/ || echo "No mlruns yet"
        echo ""
        echo "=== MLruns detailed structure ==="
        tree mlruns/ -L 3 || find mlruns/ -maxdepth 3 -type d

    - name: Upload model artifacts to GitHub
      if: success()
      uses: actions/upload-artifact@v4
      with:
        name: trained-model-${{ github.run_number }}
        path: |
          MLProject/models/
          mlruns/
        retention-days: 30

    # ==========================================
    # DOCKER BUILD & PUSH
    # ==========================================

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Login to Docker Hub
      uses: docker/login-action@v3
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}

    - name: Find latest MLflow run
      id: find_run
      run: |
        echo "ðŸ” Searching for latest MLflow run..."

        FOUND=false
        MODEL_PATH=""
        EXPERIMENT_ID=""
        RUN_ID=""

        for exp_dir in mlruns/*/; do
          exp_dir=${exp_dir%/}
          exp_name=$(basename "$exp_dir")

          echo "ðŸ“ Checking experiment directory: $exp_dir"

          for run_dir in "$exp_dir"/*/ ; do
            run_dir=${run_dir%/}
            run_name=$(basename "$run_dir")

            if [ "$run_name" = "meta.yaml" ] || [ "$run_name" = ".trash" ]; then
              continue
            fi

            if [ -d "$run_dir/artifacts/model" ]; then
              echo "âœ… Found model in: $run_dir"

              MODEL_PATH="$run_dir/artifacts/model"
              EXPERIMENT_ID="$exp_name"
              RUN_ID="$run_name"

              echo "ðŸ“¦ Model Path: $MODEL_PATH"
              echo "ðŸ“Š Experiment ID: $EXPERIMENT_ID"
              echo "ðŸ”‘ Run ID: $RUN_ID"

              echo "ðŸ“‹ Model files:"
              ls -la "$MODEL_PATH"

              FOUND=true
              break 2
            fi
          done
        done

        if [ "$FOUND" = false ]; then
          echo "âŒ No valid MLflow run with model artifacts found!"
          exit 1
        fi

        echo "experiment_id=$EXPERIMENT_ID" >> $GITHUB_OUTPUT
        echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT
        echo "model_path=$MODEL_PATH" >> $GITHUB_OUTPUT

        echo "âœ… MLflow run detection completed!"

    - name: Create Dockerfile for MLflow Model
      run: |
        MODEL_PATH="${{ steps.find_run.outputs.model_path }}"

        cat > Dockerfile << 'EOF'
        FROM python:3.9-slim

        WORKDIR /app

        COPY $MODEL_PATH ./model

        RUN pip install --no-cache-dir mlflow scikit-learn pandas numpy

        RUN if [ -f ./model/requirements.txt ]; then \
              pip install --no-cache-dir -r ./model/requirements.txt; \
            fi

        EXPOSE 8080

        ENV MLFLOW_TRACKING_URI=""
        ENV DISABLE_NGINX=true

        CMD ["mlflow", "models", "serve", "-m", "./model", "-h", "0.0.0.0", "-p", "8080", "--no-conda"]
        EOF

        echo "âœ… Dockerfile created"
        cat Dockerfile

        sed -i "s|\$MODEL_PATH|$MODEL_PATH|g" Dockerfile

        echo "âœ… Dockerfile with model path:"
        cat Dockerfile

    - name: Build Docker Image
      run: |
        IMAGE_NAME="${{ secrets.DOCKER_USERNAME }}/youtube-comment-model"

        echo "ðŸ³ Building Docker image: $IMAGE_NAME:latest"
        docker build -t $IMAGE_NAME:latest .

        echo "âœ… Docker image built successfully!"
        docker images | grep youtube-comment-model

    - name: Tag Docker Image
      run: |
        IMAGE_NAME="${{ secrets.DOCKER_USERNAME }}/youtube-comment-model"

        docker tag $IMAGE_NAME:latest $IMAGE_NAME:build-${{ github.run_number }}
        docker tag $IMAGE_NAME:latest $IMAGE_NAME:${GITHUB_SHA::7}

        echo "âœ… Docker image tagged:"
        docker images | grep youtube-comment-model

    - name: Push Docker Image to Docker Hub
      run: |
        IMAGE_NAME="${{ secrets.DOCKER_USERNAME }}/youtube-comment-model"

        echo "ðŸš€ Pushing Docker images to Docker Hub..."
        docker push $IMAGE_NAME:latest
        docker push $IMAGE_NAME:build-${{ github.run_number }}
        docker push $IMAGE_NAME:${GITHUB_SHA::7}

        echo "âœ… All images pushed successfully!"

    - name: Create Docker Hub Info File
      run: |
        IMAGE_NAME="${{ secrets.DOCKER_USERNAME }}/youtube-comment-model"

        cat > docker-hub-info.txt << EOF
        ========================================
        ðŸ³ DOCKER HUB DEPLOYMENT INFORMATION
        ========================================

        âœ… Docker Image Successfully Pushed!

        ðŸ“¦ Image Repository:
        https://hub.docker.com/r/$IMAGE_NAME

        ðŸ·ï¸  Available Tags:
        - latest
        - build-${{ github.run_number }}
        - ${GITHUB_SHA::7}

        ðŸ“¥ Pull Command:
        docker pull $IMAGE_NAME:latest

        ðŸš€ Run Command:
        docker run -p 8080:8080 $IMAGE_NAME:latest

        ========================================
        Build Information:
        - GitHub Run: ${{ github.run_number }}
        - Commit: ${GITHUB_SHA::7}
        - Branch: ${{ github.ref_name }}
        - Timestamp: $(date -u +'%Y-%m-%d %H:%M:%S UTC')
        - MLflow Experiment ID: ${{ steps.find_run.outputs.experiment_id }}
        - MLflow Run ID: ${{ steps.find_run.outputs.run_id }}
        ========================================
        EOF

        cat docker-hub-info.txt

    - name: Upload Docker Hub Info
      uses: actions/upload-artifact@v4
      with:
        name: docker-hub-info-${{ github.run_number }}
        path: docker-hub-info.txt
        retention-days: 90

    - name: Summary
      run: |
        echo "## ðŸŽ‰ CI/CD Pipeline Completed Successfully!" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### âœ… Dataset Used:" >> $GITHUB_STEP_SUMMARY
        echo "- ${{ env.DATASET_PATH }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### âœ… Artifacts Created:" >> $GITHUB_STEP_SUMMARY
        echo "- ðŸ“¦ Trained Model (GitHub Artifacts)" >> $GITHUB_STEP_SUMMARY
        echo "- ðŸ³ Docker Image (Docker Hub)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ“Š MLflow Info:" >> $GITHUB_STEP_SUMMARY
        echo "- Experiment ID: ${{ steps.find_run.outputs.experiment_id }}" >> $GITHUB_STEP_SUMMARY
        echo "- Run ID: ${{ steps.find_run.outputs.run_id }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ³ Docker Hub:" >> $GITHUB_STEP_SUMMARY
        echo "**Repository:** https://hub.docker.com/r/${{ secrets.DOCKER_USERNAME }}/youtube-comment-model" >> $GITHUB_STEP_SUMMARY
